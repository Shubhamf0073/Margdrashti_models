{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skkt4ZJDfhTU"
      },
      "source": [
        "# ğŸš— YOLOv8 Pothole & Crack Detection â€” Training on Colab\n",
        "\n",
        "This notebook trains YOLOv8 for pothole and crack detection using a **free T4 GPU** on Google Colab.\n",
        "\n",
        "## Steps:\n",
        "1. Connect to GPU runtime\n",
        "2. Clone the GitHub repo\n",
        "3. Install dependencies\n",
        "4. Download datasets from Roboflow\n",
        "5. Train (2-stage transfer learning)\n",
        "6. Download trained model\n",
        "\n",
        "---\n",
        "\n",
        "> âš ï¸ **First**: Go to **Runtime â†’ Change runtime type â†’ T4 GPU** before running any cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0pjY3msfhTW"
      },
      "source": [
        "## 1. Verify GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "krC-xtxtfhTX",
        "outputId": "181075f0-de68-4502-f588-e74ee63fe9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 12 12:17:59 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "PyTorch: 2.9.0+cu128\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-692027399.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GPU: {torch.cuda.get_device_name(0)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Memory: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDYgBonofhTX"
      },
      "source": [
        "## 2. Clone Repository & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DWAYUPgefhTY",
        "outputId": "cd5c46a5-25de-4fd3-e5ec-c0f6365fd70f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/Margdrashti_models'...\n",
            "remote: Enumerating objects: 30058, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 30058 (delta 5), reused 25 (delta 5), pack-reused 30030 (from 1)\u001b[K\n",
            "Receiving objects: 100% (30058/30058), 459.01 MiB | 30.13 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Updating files: 100% (67275/67275), done.\n",
            "\n",
            "Working directory: /content/Margdrashti_models\n",
            "total 196\n",
            "drwxr-xr-x 8 root root  4096 Feb 12 12:18 .\n",
            "drwxr-xr-x 1 root root  4096 Feb 12 12:18 ..\n",
            "drwxr-xr-x 4 root root  4096 Feb 12 12:18 data\n",
            "-rw-r--r-- 1 root root 11277 Feb 12 12:18 deploy_inference_realtime_fast.py\n",
            "-rw-r--r-- 1 root root 11535 Feb 12 12:18 deploy_inference_realtime_fast_throttled.py\n",
            "-rw-r--r-- 1 root root  9582 Feb 12 12:18 deploy_inference_realtime.py\n",
            "-rw-r--r-- 1 root root 31325 Feb 12 12:18 deploy_inference_smooth.py\n",
            "-rw-r--r-- 1 root root 15201 Feb 12 12:18 deploy_inference_yolov8.py\n",
            "-rw-r--r-- 1 root root  7653 Feb 12 12:18 draw_pothole_roi.py\n",
            "-rw-r--r-- 1 root root 18436 Feb 12 12:18 .DS_Store\n",
            "drwxr-xr-x 8 root root  4096 Feb 12 12:18 .git\n",
            "-rw-r--r-- 1 root root   321 Feb 12 12:18 .gitignore\n",
            "drwxr-xr-x 3 root root  4096 Feb 12 12:18 .idea\n",
            "-rw-r--r-- 1 root root 42656 Feb 12 12:18 Previa_Tech_Road_Audit_AI_Technical_Documentation.pdf\n",
            "-rw-r--r-- 1 root root   376 Feb 12 12:18 roi_highway_shorter.json\n",
            "drwxr-xr-x 7 root root  4096 Feb 12 12:18 scripts\n",
            "drwxr-xr-x 3 root root  4096 Feb 12 12:18 source\n",
            "drwxr-xr-x 5 root root  4096 Feb 12 12:18 video_analysis_script\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Clone the repo\n",
        "REPO_URL = \"https://github.com/Shubhamf0073/Margdrashti_models.git\"\n",
        "REPO_DIR = \"/content/Margdrashti_models\"\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(f\"Repo already cloned at {REPO_DIR}, pulling latest...\")\n",
        "    !cd {REPO_DIR} && git pull\n",
        "else:\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"\\nWorking directory: {os.getcwd()}\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0QQ_wXRzfhTY",
        "outputId": "a4cb0f9c-07ab-413d-b7ce-6a50b39538a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/91.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Ultralytics: 8.4.14\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q ultralytics roboflow pyyaml\n",
        "\n",
        "# Verify installation\n",
        "import ultralytics\n",
        "print(f\"Ultralytics: {ultralytics.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPyd76t3fhTY"
      },
      "source": [
        "## 3. Download Dataset from Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OE1X9RsPfhTY",
        "outputId": "5226cea4-1440-4dc5-f6e0-1316962672a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "YOLOV8 DATASET PREPARATION\n",
            "============================================================\n",
            "Output directory: data/pothole_crack_detection\n",
            "Temporary downloads: data/pothole_crack_detection/temp_downloads\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING ROBOFLOW DATASETS\n",
            "============================================================\n",
            "\n",
            "Downloading GeraPotHole...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in data/pothole_crack_detection/temp_downloads/GeraPotHole to yolov8:: 100% 103488/103488 [00:04<00:00, 23668.20it/s]\n",
            "\n",
            "Extracting Dataset Version Zip to data/pothole_crack_detection/temp_downloads/GeraPotHole in yolov8:: 100% 2866/2866 [00:00<00:00, 4640.48it/s]\n",
            "âœ“ Downloaded GeraPotHole to /content/Margdrashti_models/data/pothole_crack_detection/temp_downloads/GeraPotHole\n",
            "\n",
            "Downloading Kartik...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in data/pothole_crack_detection/temp_downloads/Kartik to yolov8:: 100% 119733/119733 [00:01<00:00, 65939.90it/s]\n",
            "\n",
            "Extracting Dataset Version Zip to data/pothole_crack_detection/temp_downloads/Kartik in yolov8:: 100% 2908/2908 [00:00<00:00, 5980.04it/s]\n",
            "âœ“ Downloaded Kartik to /content/Margdrashti_models/data/pothole_crack_detection/temp_downloads/Kartik\n",
            "\n",
            "============================================================\n",
            "MERGING DATASETS\n",
            "============================================================\n",
            "\n",
            "Processing GeraPotHole...\n",
            "\n",
            "Processing Kartik...\n",
            "\n",
            "Total images collected: 2875\n",
            "\n",
            "Copying 2012 images to train split...\n",
            "\n",
            "Copying 575 images to val split...\n",
            "\n",
            "Copying 288 images to test split...\n",
            "\n",
            "âœ“ Dataset merge complete!\n",
            "  Train: 2012 images\n",
            "  Val:   575 images\n",
            "  Test:  288 images\n",
            "\n",
            "âœ“ Created data/pothole_crack_detection/data.yaml\n",
            "\n",
            "data.yaml contents:\n",
            "names:\n",
            "- pothole\n",
            "- crack\n",
            "- longitudinal_crack\n",
            "- transverse_crack\n",
            "nc: 4\n",
            "path: /content/Margdrashti_models/data/pothole_crack_detection\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/val\n",
            "\n",
            "\n",
            "============================================================\n",
            "VALIDATING DATASET\n",
            "============================================================\n",
            "\n",
            "TRAIN split:\n",
            "  Images: 2012\n",
            "  Labels: 2012\n",
            "  Sample label: 0 0.50390625 0.41875 0.450390625 0.352734375\n",
            "\n",
            "VAL split:\n",
            "  Images: 575\n",
            "  Labels: 575\n",
            "  Sample label: 0 0.50234375 0.55078125 0.9953125 0.6328125\n",
            "\n",
            "TEST split:\n",
            "  Images: 288\n",
            "  Labels: 288\n",
            "  Sample label: 0 0.43671875 0.36015625 0.09609375 0.0640625\n",
            "\n",
            "âœ“ Validation passed!\n",
            "\n",
            "Cleaning up temporary files in data/pothole_crack_detection/temp_downloads...\n",
            "âœ“ Cleanup complete\n",
            "\n",
            "============================================================\n",
            "DATASET PREPARATION COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Dataset ready at: data/pothole_crack_detection\n",
            "\n",
            "Next steps:\n",
            "  1. Review the data.yaml file\n",
            "  2. Visualize some samples to verify annotations\n",
            "  3. Start training with train_yolov8.py\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ğŸ”‘ SET YOUR ROBOFLOW API KEY HERE\n",
        "# ============================================================\n",
        "ROBOFLOW_KEY = \"lcZrl8Z8hFNZYgrdN33C\"  # <-- Replace if needed\n",
        "\n",
        "!python scripts/yolov8_detection/download_datasets.py \\\n",
        "    --roboflow_key {ROBOFLOW_KEY} \\\n",
        "    --output_dir data/pothole_crack_detection \\\n",
        "    --skip_kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rcragSwCfhTY",
        "outputId": "486d031d-480c-4c6a-af3d-6ec22efac495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- pothole\n",
            "- crack\n",
            "- longitudinal_crack\n",
            "- transverse_crack\n",
            "nc: 4\n",
            "path: /content/Margdrashti_models/data/pothole_crack_detection\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/val\n",
            "\n",
            "Train images:\n",
            "2012\n",
            "Val images:\n",
            "575\n",
            "Test images:\n",
            "288\n"
          ]
        }
      ],
      "source": [
        "# Verify dataset\n",
        "!cat data/pothole_crack_detection/data.yaml\n",
        "print()\n",
        "!echo \"Train images:\" && ls data/pothole_crack_detection/images/train/ | wc -l\n",
        "!echo \"Val images:\"   && ls data/pothole_crack_detection/images/val/ | wc -l\n",
        "!echo \"Test images:\"  && ls data/pothole_crack_detection/images/test/ | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox_G7FxRfhTZ"
      },
      "source": [
        "## 4. Fix data.yaml Path for Colab\n",
        "\n",
        "The data.yaml has an absolute path from local machine. We need to update it for Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NB14g-CJfhTZ",
        "outputId": "4897e281-0aa1-40d0-c251-1f8a5991a230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated data.yaml:\n",
            "names:\n",
            "- pothole\n",
            "- crack\n",
            "- longitudinal_crack\n",
            "- transverse_crack\n",
            "nc: 4\n",
            "path: /content/Margdrashti_models/data/pothole_crack_detection\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/val\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "yaml_path = \"data/pothole_crack_detection/data.yaml\"\n",
        "\n",
        "with open(yaml_path, 'r') as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "# Update to Colab absolute path\n",
        "data['path'] = f\"{REPO_DIR}/data/pothole_crack_detection\"\n",
        "\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data, f, default_flow_style=False)\n",
        "\n",
        "print(\"Updated data.yaml:\")\n",
        "!cat {yaml_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TTM7LnnfhTZ"
      },
      "source": [
        "## 5. Train YOLOv8 (Two-Stage Transfer Learning)\n",
        "\n",
        "- **Stage 1** (15 epochs): Backbone frozen, trains detection head only\n",
        "- **Stage 2** (30 epochs): Full fine-tuning with lower learning rate\n",
        "\n",
        "On a T4 GPU this should take **~20-40 minutes** total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yk8gBqzlfhTZ",
        "outputId": "e142a75d-3d75-4a12-e4b0-1bf91b83a180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "                 YOLOV8 TWO-STAGE TRAINING                  \n",
            "============================================================\n",
            "\n",
            "Start time: 2026-02-12 12:19:16\n",
            "\n",
            "Configuration:\n",
            "  Data: data/pothole_crack_detection/data.yaml\n",
            "  Model: yolov8n.pt\n",
            "  Batch size: 32\n",
            "  Image size: 640\n",
            "  Device: 0\n",
            "  Output: scripts/runs\n",
            "\n",
            "âœ“ GPU detected: Tesla T4 (14.6 GB)\n",
            "\n",
            "============================================================\n",
            "                     DATASET VALIDATION                     \n",
            "============================================================\n",
            "Dataset: data/pothole_crack_detection/data.yaml\n",
            "Classes (4): ['pothole', 'crack', 'longitudinal_crack', 'transverse_crack']\n",
            "Train: 2012 images at /content/Margdrashti_models/data/pothole_crack_detection/images/train\n",
            "Val  : 575 images at /content/Margdrashti_models/data/pothole_crack_detection/images/val\n",
            "Test : 288 images at /content/Margdrashti_models/data/pothole_crack_detection/images/test\n",
            "\n",
            "============================================================\n",
            "             STAGE 1: FROZEN BACKBONE TRAINING              \n",
            "============================================================\n",
            "\n",
            "Initializing YOLOv8 from yolov8n.pt...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 130.8MB/s 0.0s\n",
            "\n",
            "Freezing first 10 layers...\n",
            "Frozen parameters: 3,157,200\n",
            "Trainable parameters: 0\n",
            "\n",
            "Training configuration:\n",
            "  Epochs: 15\n",
            "  Batch size: 32\n",
            "  Image size: 640\n",
            "  Initial LR: 0.01\n",
            "  Device: 0\n",
            "\n",
            "Starting Stage 1 training...\n",
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/pothole_crack_detection/data.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov8n_stage1, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=scripts/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage1, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 27.6MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, 16, None, [64, 128, 256]] \n",
            "Model summary: 130 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 91.3MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1984.2Â±696.3 MB/s, size: 89.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Margdrashti_models/data/pothole_crack_detection/labels/train... 2012 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2012/2012 2.4Kit/s 0.8s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Margdrashti_models/data/pothole_crack_detection/labels/train.cache\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.3GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2012/2012 304.0it/s 6.6s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.9 ms, read: 464.3Â±96.1 MB/s, size: 66.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Margdrashti_models/data/pothole_crack_detection/labels/val... 575 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 575/575 1.6Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Margdrashti_models/data/pothole_crack_detection/labels/val.cache\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 575/575 138.7it/s 4.1s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Plotting labels to /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage1/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage1\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      4.39G       2.15      2.539      2.036        267        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6it/s 5.5s\n",
            "                   all        575       2584    0.00763     0.0418    0.00187   0.000596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      5.35G      2.162      2.235      2.055        176        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.4it/s 6.4s\n",
            "                   all        575       2584       0.15      0.151     0.0725     0.0241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      5.37G       2.09      2.155      2.022        168        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.1s\n",
            "                   all        575       2584     0.0306     0.0681    0.00864    0.00259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      5.38G      2.064      2.084       1.97        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.5it/s 6.1s\n",
            "                   all        575       2584      0.252      0.309      0.189     0.0606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15       5.4G       2.03      2.014      1.915        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.1s\n",
            "                   all        575       2584      0.329      0.286      0.223     0.0737\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15      5.42G      2.074      2.034      2.025        108        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.2it/s 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.4s\n",
            "                   all        575       2584      0.371      0.324      0.276     0.0934\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15      5.43G      2.034      1.942      2.022        152        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        575       2584      0.387      0.363       0.32      0.116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/15      5.45G      2.004      1.901       1.97        162        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.4s\n",
            "                   all        575       2584       0.52      0.457      0.447      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/15      5.47G      1.956       1.82      1.922        117        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.6it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6it/s 5.7s\n",
            "                   all        575       2584      0.458      0.399      0.385      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/15      5.48G       1.94       1.75        1.9         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.6it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.1s\n",
            "                   all        575       2584      0.511      0.442      0.458      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/15       5.5G      1.946      1.724      1.911        108        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 25.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.4s\n",
            "                   all        575       2584      0.565      0.519      0.511      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/15      5.52G      1.903      1.678      1.865        120        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.6it/s 24.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6it/s 5.6s\n",
            "                   all        575       2584      0.616      0.572      0.598      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/15      5.54G      1.868      1.633      1.842         82        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 24.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.2s\n",
            "                   all        575       2584      0.642      0.527      0.605      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/15      5.55G      1.847      1.589      1.828        131        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6it/s 5.6s\n",
            "                   all        575       2584      0.637      0.556      0.613      0.273\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/15      5.57G      1.825      1.552      1.807         74        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 25.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 4.9s\n",
            "                   all        575       2584      0.667      0.566      0.641      0.291\n",
            "\n",
            "15 epochs completed in 0.131 hours.\n",
            "Optimizer stripped from /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage1/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage1/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage1/weights/best.pt...\n",
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "Model summary (fused): 73 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.3it/s 7.2s\n",
            "                   all        575       2584      0.666       0.57      0.641      0.291\n",
            "               pothole        574       2584      0.666       0.57      0.641      0.291\n",
            "Speed: 1.7ms preprocess, 2.9ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage1\u001b[0m\n",
            "\n",
            "============================================================\n",
            "STAGE 1 COMPLETE\n",
            "============================================================\n",
            "\n",
            "Best model saved to: scripts/runs/yolov8n_stage1/weights/best.pt\n",
            "\n",
            "Final metrics:\n",
            "  mAP@50: 0.6413\n",
            "  mAP@50-95: 0.2909\n",
            "  Precision: 0.6665\n",
            "  Recall: 0.5700\n",
            "\n",
            "============================================================\n",
            "                 STAGE 2: FULL FINE-TUNING                  \n",
            "============================================================\n",
            "\n",
            "Loading model from Stage 1: scripts/runs/yolov8n_stage1/weights/best.pt...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Margdrashti_models/scripts/yolov8_detection/train_yolov8.py\", line 451, in <module>\n",
            "    main()\n",
            "  File \"/content/Margdrashti_models/scripts/yolov8_detection/train_yolov8.py\", line 432, in main\n",
            "    final_model = train_stage2(args, stage1_model)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Margdrashti_models/scripts/yolov8_detection/train_yolov8.py\", line 198, in train_stage2\n",
            "    model = YOLO(str(stage1_model))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/model.py\", line 76, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 144, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 283, in _load\n",
            "    self.model, self.ckpt = load_checkpoint(weights)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 1507, in load_checkpoint\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 1455, in torch_safe_load\n",
            "    ckpt = torch_load(file, map_location=\"cpu\")\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/patches.py\", line 158, in torch_load\n",
            "    return torch.load(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1484, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 759, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 740, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'scripts/runs/yolov8n_stage1/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!python scripts/yolov8_detection/train_yolov8.py \\\n",
        "    --data data/pothole_crack_detection/data.yaml \\\n",
        "    --model yolov8n.pt \\\n",
        "    --epochs_stage1 15 \\\n",
        "    --epochs_stage2 30 \\\n",
        "    --batch 32 \\\n",
        "    --device 0 \\\n",
        "    --cache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/Margdrashti_models && git pull origin master"
      ],
      "metadata": {
        "id": "jJEMLcFY2FMJ",
        "outputId": "f4209321-d2dd-4ebb-a80b-9d0c10684323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 589 bytes | 147.00 KiB/s, done.\n",
            "From https://github.com/Shubhamf0073/Margdrashti_models\n",
            " * branch              master     -> FETCH_HEAD\n",
            "   3a66c5e9..33f9a694  master     -> origin/master\n",
            "Updating 3a66c5e9..33f9a694\n",
            "Fast-forward\n",
            " scripts/yolov8_detection/train_yolov8.py | 6 \u001b[32m++++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 4 insertions(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/yolov8_detection/train_yolov8.py \\\n",
        "    --data data/pothole_crack_detection/data.yaml \\\n",
        "    --model yolov8n.pt \\\n",
        "    --epochs_stage2 30 \\\n",
        "    --batch 32 \\\n",
        "    --device 0 \\\n",
        "    --cache \\\n",
        "    --skip_stage1 \\\n",
        "    --resume_stage1 runs/detect/scripts/runs/yolov8n_stage1/weights/best.pt"
      ],
      "metadata": {
        "id": "fFkYnJJf2IlU",
        "outputId": "c12e12d8-2233-4c61-b238-10aaeac9f26b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "                 YOLOV8 TWO-STAGE TRAINING                  \n",
            "============================================================\n",
            "\n",
            "Start time: 2026-02-12 12:34:40\n",
            "\n",
            "Configuration:\n",
            "  Data: data/pothole_crack_detection/data.yaml\n",
            "  Model: yolov8n.pt\n",
            "  Batch size: 32\n",
            "  Image size: 640\n",
            "  Device: 0\n",
            "  Output: scripts/runs\n",
            "\n",
            "âœ“ GPU detected: Tesla T4 (14.6 GB)\n",
            "\n",
            "============================================================\n",
            "                     DATASET VALIDATION                     \n",
            "============================================================\n",
            "Dataset: data/pothole_crack_detection/data.yaml\n",
            "Classes (4): ['pothole', 'crack', 'longitudinal_crack', 'transverse_crack']\n",
            "Train: 2012 images at /content/Margdrashti_models/data/pothole_crack_detection/images/train\n",
            "Val  : 575 images at /content/Margdrashti_models/data/pothole_crack_detection/images/val\n",
            "Test : 288 images at /content/Margdrashti_models/data/pothole_crack_detection/images/test\n",
            "\n",
            "Skipping Stage 1, using checkpoint: runs/detect/scripts/runs/yolov8n_stage1/weights/best.pt\n",
            "\n",
            "============================================================\n",
            "                 STAGE 2: FULL FINE-TUNING                  \n",
            "============================================================\n",
            "\n",
            "Loading model from Stage 1: runs/detect/scripts/runs/yolov8n_stage1/weights/best.pt...\n",
            "\n",
            "Unfreezing all layers...\n",
            "Trainable parameters: 3,011,628\n",
            "\n",
            "Training configuration:\n",
            "  Epochs: 30\n",
            "  Batch size: 32\n",
            "  Image size: 640\n",
            "  Initial LR: 0.001 (10x lower than Stage 1)\n",
            "  LR schedule: Cosine annealing\n",
            "  Device: 0\n",
            "\n",
            "Starting Stage 2 training...\n",
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data/pothole_crack_detection/data.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=runs/detect/scripts/runs/yolov8n_stage1/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov8n_stage2, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=False, profile=False, project=scripts/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, 16, None, [64, 128, 256]] \n",
            "Model summary: 130 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2407.7Â±1016.7 MB/s, size: 89.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Margdrashti_models/data/pothole_crack_detection/labels/train.cache... 2012 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2012/2012 401.9Mit/s 0.0s\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.3GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2012/2012 319.4it/s 6.3s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1049.7Â±707.3 MB/s, size: 66.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Margdrashti_models/data/pothole_crack_detection/labels/val.cache... 575 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 575/575 33.5Mit/s 0.0s\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 575/575 106.0it/s 5.4s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Plotting labels to /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      4.38G      1.895      1.724      1.814        267        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.2it/s 29.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6it/s 5.5s\n",
            "                   all        575       2584      0.613      0.545      0.581      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      5.34G      1.842      1.663      1.768        176        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.3s\n",
            "                   all        575       2584      0.615      0.558      0.602      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      5.36G      1.813      1.618      1.756        168        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.4s\n",
            "                   all        575       2584      0.627       0.57      0.623      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      5.36G      1.801      1.618       1.74        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.3s\n",
            "                   all        575       2584      0.657      0.553       0.63      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      5.36G      1.797      1.614      1.722        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.5s\n",
            "                   all        575       2584      0.639      0.569      0.626      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      5.36G      1.805      1.597      1.733        232        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.3s\n",
            "                   all        575       2584      0.677      0.565      0.646      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      5.36G      1.788      1.588      1.721        209        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        575       2584      0.655      0.574      0.643       0.29\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      5.36G      1.775      1.567      1.715        202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 25.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.4it/s 6.2s\n",
            "                   all        575       2584       0.64      0.588      0.647      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      5.37G       1.77       1.55      1.708        236        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 4.9s\n",
            "                   all        575       2584      0.695      0.569      0.661        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      5.37G      1.759      1.543      1.703        167        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.5it/s 5.9s\n",
            "                   all        575       2584      0.717      0.593       0.68      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      5.37G      1.746      1.535        1.7        204        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.2s\n",
            "                   all        575       2584      0.701      0.586      0.666      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      5.37G      1.755      1.512      1.688        150        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.4it/s 6.4s\n",
            "                   all        575       2584      0.703      0.617      0.692      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      5.37G       1.75      1.506       1.69        188        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 25.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.2s\n",
            "                   all        575       2584      0.708      0.611      0.689      0.317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      5.37G      1.745      1.515      1.701        242        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.5it/s 6.1s\n",
            "                   all        575       2584      0.688      0.596      0.674      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      5.37G      1.735      1.496      1.691        210        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.4s\n",
            "                   all        575       2584      0.702      0.612      0.692      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      5.37G      1.726      1.488      1.687        202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.4it/s 6.3s\n",
            "                   all        575       2584      0.722      0.621      0.705      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      5.37G      1.712      1.468      1.672        199        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.1s\n",
            "                   all        575       2584      0.692      0.627      0.694      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      5.37G      1.718      1.457      1.661        197        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.4it/s 6.4s\n",
            "                   all        575       2584      0.712      0.618      0.696      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      5.37G       1.72      1.463      1.675        231        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.2s\n",
            "                   all        575       2584      0.708      0.637      0.705      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      5.39G      1.699      1.442      1.649        155        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.4it/s 6.3s\n",
            "                   all        575       2584       0.72      0.631      0.707      0.336\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      5.39G      1.751      1.448      1.737         96        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.1it/s 30.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.5it/s 6.1s\n",
            "                   all        575       2584      0.711      0.627      0.705      0.332\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      5.39G      1.719      1.395      1.715        109        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.1s\n",
            "                   all        575       2584      0.719      0.634      0.711      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      5.39G      1.717       1.38      1.708        118        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.7s\n",
            "                   all        575       2584      0.735       0.63      0.714      0.343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      5.39G        1.7      1.358      1.701        113        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 25.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6it/s 5.5s\n",
            "                   all        575       2584      0.732      0.637       0.72      0.347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      5.39G      1.692      1.331      1.698        142        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.6it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        575       2584      0.729      0.642      0.721      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      5.39G      1.703      1.341      1.704        121        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.6it/s 24.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.3s\n",
            "                   all        575       2584      0.732      0.648      0.727      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      5.39G      1.693      1.342      1.696        114        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.5it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.4it/s 6.5s\n",
            "                   all        575       2584      0.729      0.645      0.723      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      5.39G      1.694      1.324      1.691         97        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.4it/s 26.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.1s\n",
            "                   all        575       2584       0.73      0.652      0.727      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      5.39G      1.685      1.329      1.696        121        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.6it/s 24.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6it/s 5.6s\n",
            "                   all        575       2584      0.736      0.646      0.726      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      5.39G      1.694      1.326      1.691         99        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.6it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.5it/s 6.0s\n",
            "                   all        575       2584      0.737       0.65      0.726      0.352\n",
            "\n",
            "30 epochs completed in 0.266 hours.\n",
            "Optimizer stripped from /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/best.pt...\n",
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "Model summary (fused): 73 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.2it/s 7.3s\n",
            "                   all        575       2584      0.736      0.646      0.726      0.352\n",
            "               pothole        574       2584      0.736      0.646      0.726      0.352\n",
            "Speed: 1.5ms preprocess, 2.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2\u001b[0m\n",
            "\n",
            "============================================================\n",
            "STAGE 2 COMPLETE\n",
            "============================================================\n",
            "\n",
            "Best model saved to: /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/best.pt\n",
            "\n",
            "Final metrics:\n",
            "  mAP@50: 0.7263\n",
            "  mAP@50-95: 0.3524\n",
            "  Precision: 0.7358\n",
            "  Recall: 0.6463\n",
            "\n",
            "============================================================\n",
            "                     TRAINING COMPLETE                      \n",
            "============================================================\n",
            "\n",
            "End time: 2026-02-12 12:51:11\n",
            "\n",
            "Final model: /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/best.pt\n",
            "\n",
            "Next steps:\n",
            "  1. Validate the model:\n",
            "     python scripts/yolov8_detection/validate_yolov8.py --model /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/best.pt --data data/pothole_crack_detection/data.yaml\n",
            "\n",
            "  2. Run inference:\n",
            "     python deploy_inference_yolov8.py --model /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/best.pt --roi roi_highway_shorter.json --source <video>\n",
            "\n",
            "  3. Export for deployment:\n",
            "     python scripts/yolov8_detection/export_model.py --model /content/Margdrashti_models/runs/detect/scripts/runs/yolov8n_stage2/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btifHs14fhTZ"
      },
      "source": [
        "## 6. View Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v7ZLBnwHfhTZ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "# Show training curves\n",
        "for stage in ['yolov8n_stage1', 'yolov8n_stage2']:\n",
        "    results_img = f\"scripts/runs/{stage}/results.png\"\n",
        "    if os.path.exists(results_img):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"{stage} Results\")\n",
        "        print(f\"{'='*50}\")\n",
        "        display(Image(filename=results_img, width=800))\n",
        "\n",
        "# Show confusion matrix if available\n",
        "for stage in ['yolov8n_stage1', 'yolov8n_stage2']:\n",
        "    cm_img = f\"scripts/runs/{stage}/confusion_matrix.png\"\n",
        "    if os.path.exists(cm_img):\n",
        "        print(f\"\\n{stage} Confusion Matrix\")\n",
        "        display(Image(filename=cm_img, width=600))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkD5LbR5fhTZ"
      },
      "source": [
        "## 7. Download Trained Model\n",
        "\n",
        "Download the best model weights to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "H8yR8dZTfhTa",
        "outputId": "61445daa-be16-4490-a8c0-999964d47e5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ No trained model found. Check training output above for errors.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Path to the best model from Stage 2\n",
        "best_model = \"scripts/runs/yolov8n_stage2/weights/best.pt\"\n",
        "\n",
        "if os.path.exists(best_model):\n",
        "    print(f\"Best model: {best_model}\")\n",
        "    print(f\"Size: {os.path.getsize(best_model) / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "    # Also zip the entire runs directory for full results\n",
        "    shutil.make_archive(\"/content/training_results\", 'zip', \"scripts/runs\")\n",
        "\n",
        "    print(\"\\nğŸ“¥ Downloading best model weight...\")\n",
        "    files.download(best_model)\n",
        "\n",
        "    print(\"\\nğŸ“¥ Downloading full results archive...\")\n",
        "    files.download(\"/content/training_results.zip\")\n",
        "else:\n",
        "    # Fallback to Stage 1 model\n",
        "    fallback = \"scripts/runs/yolov8n_stage1/weights/best.pt\"\n",
        "    if os.path.exists(fallback):\n",
        "        print(f\"Stage 2 not found, downloading Stage 1 model: {fallback}\")\n",
        "        files.download(fallback)\n",
        "    else:\n",
        "        print(\"âŒ No trained model found. Check training output above for errors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovmn23sKfhTa"
      },
      "source": [
        "## 8. (Optional) Test Inference on Colab\n",
        "\n",
        "Quick test on a sample image from the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyS1QLb4fhTa"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Load trained model\n",
        "model = YOLO(\"scripts/runs/yolov8n_stage2/weights/best.pt\")\n",
        "\n",
        "# Get a test image\n",
        "test_images = glob.glob(\"data/pothole_crack_detection/images/test/*\")\n",
        "if test_images:\n",
        "    results = model.predict(\n",
        "        source=test_images[:5],\n",
        "        conf=0.5,\n",
        "        save=True,\n",
        "        project=\"test_predictions\",\n",
        "        name=\"samples\",\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "    # Display predictions\n",
        "    for img_path in glob.glob(\"test_predictions/samples/*\"):\n",
        "        display(Image(filename=img_path, width=600))\n",
        "else:\n",
        "    print(\"No test images found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrgAKPBPfhTa"
      },
      "source": [
        "---\n",
        "## âœ… Next Steps (on your local machine)\n",
        "\n",
        "After downloading `best.pt`, place it at `scripts/runs/yolov8n_stage2/weights/best.pt` in your local repo and run:\n",
        "\n",
        "```bash\n",
        "# On a video file\n",
        "python deploy_inference_yolov8.py \\\n",
        "    --model scripts/runs/yolov8n_stage2/weights/best.pt \\\n",
        "    --roi roi_highway_shorter.json \\\n",
        "    --source path/to/your/video.mp4 \\\n",
        "    --confidence 0.5 \\\n",
        "    --save_output results/output.mp4\n",
        "\n",
        "# On webcam\n",
        "python deploy_inference_yolov8.py \\\n",
        "    --model scripts/runs/yolov8n_stage2/weights/best.pt \\\n",
        "    --roi roi_highway_shorter.json \\\n",
        "    --source 0\n",
        "```"
      ]
    }
  ]
}